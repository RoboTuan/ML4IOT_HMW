{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "costraint3_prova.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOG5ln2YyxNJK1F9OpacwEB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoboTuan/ML4IOT_HMW/blob/main/HMW2/costraint3_prova.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lhAFmUjhbiEb",
        "outputId": "363558ec-ecbe-468e-b77b-b30fbdb4ad49"
      },
      "source": [
        "!pip uninstall tensorflow \r\n",
        "!pip install tensorflow===2.3.0\r\n",
        "!pip install -q tensorflow-model-optimization"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.4.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.4.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.4.0\n",
            "Collecting tensorflow===2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/ae/0b08f53498417914f2274cc3b5576d2b83179b0cbb209457d0fde0152174/tensorflow-2.3.0-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 48kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.3.0) (3.12.4)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.3.0) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.3.0) (3.3.0)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/a9/b1bc4c935ed063766bce7d3e8c7b20bd52e515ff1c732b02caacf7918e5a/numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.3.0) (1.32.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.3.0) (0.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.3.0) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.3.0) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.3.0) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.3.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.3.0) (0.36.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.3.0) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.3.0) (2.4.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.3.0) (0.10.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.3.0) (2.10.0)\n",
            "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/ed/5853ec0ae380cba4588eab1524e18ece1583b65f7ae0e97321f5ff9dfd60/tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 55.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow===2.3.0) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow===2.3.0) (50.3.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow===2.3.0) (3.3.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow===2.3.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow===2.3.0) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow===2.3.0) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow===2.3.0) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow===2.3.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (3.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (2020.12.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (4.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (3.7.4.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow===2.3.0) (3.1.0)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: numpy 1.19.4\n",
            "    Uninstalling numpy-1.19.4:\n",
            "      Successfully uninstalled numpy-1.19.4\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "Successfully installed numpy-1.18.5 tensorflow-2.3.0 tensorflow-estimator-2.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██                              | 10kB 26.1MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20kB 32.6MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 30kB 28.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 40kB 20.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 51kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 61kB 14.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 71kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 81kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 92kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 102kB 13.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 112kB 13.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 122kB 13.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 133kB 13.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 143kB 13.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 153kB 13.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 163kB 13.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 13.3MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnVReoPIboT1",
        "outputId": "0524f791-e973-48f7-9b8a-4dbde837798c"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "from tensorflow import keras\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "from scipy import signal\r\n",
        "from zipfile import ZipFile\r\n",
        "import tensorflow_model_optimization as tfmot\r\n",
        "import tensorflow.lite as tflite\r\n",
        "from tensorflow_model_optimization.python.core.api.sparsity import keras as sparsity\r\n",
        "import zlib\r\n",
        "import sys\r\n",
        "\r\n",
        "seed = 42\r\n",
        "tf.random.set_seed(seed)\r\n",
        "np.random.seed(seed)\r\n",
        "\r\n",
        "ROOT_DIR = \"./\"\r\n",
        "\r\n",
        "model_type = \"DS-CNN\"\r\n",
        "mfcc = True\r\n",
        "alpha = 0.4\r\n",
        "PRUNING = False\r\n",
        "\r\n",
        "zip_path = tf.keras.utils.get_file(\r\n",
        "        origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\r\n",
        "        fname='mini_speech_commands.zip',\r\n",
        "        extract=True,\r\n",
        "        cache_dir='.', cache_subdir='data')\r\n",
        "data_dir = os.path.join('.', 'data', 'mini_speech_commands')\r\n",
        "filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\r\n",
        "filenames = tf.random.shuffle(filenames)\r\n",
        "num_samples = len(filenames)\r\n",
        "total = 8000\r\n",
        "\r\n",
        "train_files = tf.strings.split(tf.io.read_file(ROOT_DIR +'kws_train_split.txt'),sep='\\n')[:-1]\r\n",
        "val_files= tf.strings.split(tf.io.read_file(ROOT_DIR +'kws_val_split.txt'),sep='\\n')[:-1]\r\n",
        "test_files = tf.strings.split(tf.io.read_file(ROOT_DIR +'kws_test_split.txt'),sep='\\n')[:-1]\r\n",
        "\r\n",
        "LABELS = np.array(tf.io.gfile.listdir(str(data_dir)))\r\n",
        "LABELS = LABELS[LABELS != 'README.md']\r\n",
        "\r\n",
        "\r\n",
        "class SignalGenerator:\r\n",
        "    def __init__(self, labels, sampling_rate, frame_length, frame_step,\r\n",
        "            num_mel_bins=None, lower_frequency=None, upper_frequency=None,\r\n",
        "            num_coefficients=None, mfcc=False, resampling_rate = None):\r\n",
        "\r\n",
        "        self.labels = labels\r\n",
        "\r\n",
        "        # Added resampling_rte\r\n",
        "        self.sampling_rate = sampling_rate\r\n",
        "        self.resampling_rate = resampling_rate\r\n",
        "\r\n",
        "        self.frame_length = frame_length\r\n",
        "        self.frame_step = frame_step\r\n",
        "\r\n",
        "        self.lower_frequency = lower_frequency\r\n",
        "        self.upper_frequency = upper_frequency\r\n",
        "\r\n",
        "        self.num_mel_bins = num_mel_bins\r\n",
        "        self.num_coefficients = num_coefficients\r\n",
        "\r\n",
        "        num_spectrogram_bins = (frame_length) // 2 + 1\r\n",
        "\r\n",
        "\r\n",
        "        if self.resampling_rate is not None:\r\n",
        "            # Step for resampling\r\n",
        "            self.step = int(self.sampling_rate/self.resampling_rate)\r\n",
        "            \r\n",
        "            if mfcc is True:\r\n",
        "                self.linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\r\n",
        "                        self.num_mel_bins, num_spectrogram_bins, self.resampling_rate,\r\n",
        "                        self.lower_frequency, self.upper_frequency)\r\n",
        "                self.preprocess = self.preprocess_with_mfcc\r\n",
        "            else:\r\n",
        "                self.preprocess = self.preprocess_with_stft\r\n",
        "\r\n",
        "        else:\r\n",
        "            self.step = 1\r\n",
        "            \r\n",
        "            if mfcc is True:\r\n",
        "                self.linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\r\n",
        "                        self.num_mel_bins, num_spectrogram_bins, self.sampling_rate,\r\n",
        "                        self.lower_frequency, self.upper_frequency)\r\n",
        "                self.preprocess = self.preprocess_with_mfcc\r\n",
        "            else:\r\n",
        "                self.preprocess = self.preprocess_with_stft\r\n",
        "\r\n",
        "    def read(self, file_path):\r\n",
        "        parts = tf.strings.split(file_path, os.path.sep)\r\n",
        "        label = parts[-2]\r\n",
        "        label_id = tf.argmax(label == self.labels)\r\n",
        "        audio_binary = tf.io.read_file(file_path)\r\n",
        "        audio, _ = tf.audio.decode_wav(audio_binary)\r\n",
        "        audio = tf.squeeze(audio, axis=1)\r\n",
        "\r\n",
        "        #print(self.step)\r\n",
        "\r\n",
        "        audio = audio[::self.step]\r\n",
        "        return audio, label_id\r\n",
        "\r\n",
        "\r\n",
        "    def pad(self, audio):\r\n",
        "        if self.resampling_rate is not None:\r\n",
        "            rate = self.resampling_rate\r\n",
        "        else:\r\n",
        "            rate = self.sampling_rate\r\n",
        "        zero_padding = tf.zeros([rate] - tf.shape(audio), dtype=tf.float32)\r\n",
        "        #print(self.sampling_rate)\r\n",
        "        audio = tf.concat([audio, zero_padding], 0)\r\n",
        "        audio.set_shape([rate])\r\n",
        "\r\n",
        "        return audio\r\n",
        "\r\n",
        "    def get_spectrogram(self, audio):\r\n",
        "        stft = tf.signal.stft(audio, frame_length=self.frame_length,\r\n",
        "                frame_step=self.frame_step, fft_length=self.frame_length)\r\n",
        "        spectrogram = tf.abs(stft)\r\n",
        "\r\n",
        "        return spectrogram\r\n",
        "\r\n",
        "    def get_mfccs(self, spectrogram):\r\n",
        "        mel_spectrogram = tf.tensordot(spectrogram,\r\n",
        "                self.linear_to_mel_weight_matrix, 1)\r\n",
        "        log_mel_spectrogram = tf.math.log(mel_spectrogram + 1.e-6)\r\n",
        "        mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrogram)\r\n",
        "        mfccs = mfccs[..., :self.num_coefficients]\r\n",
        "\r\n",
        "        return mfccs\r\n",
        "\r\n",
        "    def preprocess_with_stft(self, file_path):\r\n",
        "        audio, label = self.read(file_path)\r\n",
        "        audio = self.pad(audio)\r\n",
        "        spectrogram = self.get_spectrogram(audio)\r\n",
        "        spectrogram = tf.expand_dims(spectrogram, -1)\r\n",
        "        spectrogram = tf.image.resize(spectrogram, [32, 32])\r\n",
        "\r\n",
        "        return spectrogram, label\r\n",
        "\r\n",
        "    def preprocess_with_mfcc(self, file_path):\r\n",
        "        audio, label = self.read(file_path)\r\n",
        "        audio = self.pad(audio)\r\n",
        "        spectrogram = self.get_spectrogram(audio)\r\n",
        "        mfccs = self.get_mfccs(spectrogram)\r\n",
        "        mfccs = tf.expand_dims(mfccs, -1)\r\n",
        "\r\n",
        "        return mfccs, label\r\n",
        "\r\n",
        "    def make_dataset(self, files, train):\r\n",
        "        ds = tf.data.Dataset.from_tensor_slices(files)\r\n",
        "        ds = ds.map(self.preprocess, num_parallel_calls=4)\r\n",
        "        ds = ds.batch(32)\r\n",
        "        ds = ds.cache()\r\n",
        "        if train is True:\r\n",
        "            ds = ds.shuffle(100, reshuffle_each_iteration=True)\r\n",
        "\r\n",
        "        return ds\r\n",
        "    \r\n",
        "\r\n",
        "\r\n",
        "STFT_OPTIONS = {'frame_length': 256, 'frame_step': 128, 'mfcc': False}\r\n",
        "\r\n",
        "# By default l=0.04 and s=0.02\r\n",
        "# 640 = 16000 * 0.04\r\n",
        "# 320 = 16000 * 0.02\r\n",
        "\r\n",
        "# new_frame_length = resampling_rate * 0.04\r\n",
        "# new_frame_step = resampling_rate * 0.02\r\n",
        "\r\n",
        "#MFCC_OPTIONS = {'frame_length': 640, 'frame_step': 320, 'mfcc': True,\r\n",
        "MFCC_OPTIONS = {'frame_length': 320, 'frame_step': 160, 'mfcc': True,\r\n",
        "        'lower_frequency': 20, 'upper_frequency': 4000, 'num_mel_bins': 40,\r\n",
        "        #'lower_frequency': 20, 'upper_frequency': 4000, 'num_mel_bins': 20,\r\n",
        "        'num_coefficients': 10}\r\n",
        "\r\n",
        "\r\n",
        "if mfcc is True:\r\n",
        "    options = MFCC_OPTIONS\r\n",
        "    strides = [2, 1]\r\n",
        "else:\r\n",
        "    options = STFT_OPTIONS\r\n",
        "    strides = [2, 2]\r\n",
        "\r\n",
        "\r\n",
        "generator = SignalGenerator(LABELS, sampling_rate = 16000, resampling_rate=8000, **options)\r\n",
        "#generator = SignalGenerator(LABELS, 8000, **options)\r\n",
        "train_ds = generator.make_dataset(train_files, True)\r\n",
        "val_ds = generator.make_dataset(val_files, False)\r\n",
        "test_ds = generator.make_dataset(test_files, False)\r\n",
        "units=8\r\n",
        "\r\n",
        "# print(train_ds)\r\n",
        "# sys.exit()\r\n",
        "\r\n",
        "\r\n",
        "# for elem in val_ds:\r\n",
        "#     print()\r\n",
        "#     print()\r\n",
        "#     print(elem[0].shape, elem[1].shape)\r\n",
        "#     print()\r\n",
        "#     print()\r\n",
        "#     sys.exit()\r\n",
        "\r\n",
        "# RE DO THE TEST DATASET IF WHEN CHANGING STFT OR MFCC\r\n",
        "dataset_dir= ROOT_DIR + \"/test_ds_{}\".format(mfcc)\r\n",
        "tf.data.experimental.save(test_ds, dataset_dir)\r\n",
        "\r\n",
        "if model_type == \"MLP\":\r\n",
        "    model = keras.Sequential([\r\n",
        "        keras.layers.Flatten(),\r\n",
        "        keras.layers.Dense(units=int(256*alpha), activation='relu'),\r\n",
        "        keras.layers.Dense(units=int(256*alpha), activation='relu'),\r\n",
        "        keras.layers.Dense(units=int(256*alpha), activation='relu'),\r\n",
        "        keras.layers.Dense(units=8)\r\n",
        "    ])\r\n",
        "\r\n",
        "elif model_type == \"CNN-2D\":\r\n",
        "    model = keras.Sequential([\r\n",
        "        keras.layers.Conv2D(filters=int(128*alpha), kernel_size=[3, 3], strides=strides, use_bias=False),\r\n",
        "        keras.layers.BatchNormalization(momentum=0.1),\r\n",
        "        keras.layers.ReLU(),\r\n",
        "        keras.layers.Conv2D(filters=int(128*alpha), kernel_size=[3, 3], strides=strides, use_bias=False),\r\n",
        "        keras.layers.BatchNormalization(momentum=0.1),\r\n",
        "        keras.layers.ReLU(),\r\n",
        "        keras.layers.Conv2D(filters=int(128*alpha), kernel_size=[3, 3], strides=strides, use_bias=False),\r\n",
        "        keras.layers.BatchNormalization(momentum=0.1),\r\n",
        "        keras.layers.ReLU(),\r\n",
        "        keras.layers.GlobalAveragePooling2D(),\r\n",
        "        keras.layers.Dense(units=8)\r\n",
        "    ])\r\n",
        "\r\n",
        "elif model_type == \"DS-CNN\":\r\n",
        "    model = keras.Sequential([\r\n",
        "        keras.layers.Conv2D(filters=int(alpha*256), kernel_size=[3, 3], strides=strides, use_bias=False),\r\n",
        "        keras.layers.BatchNormalization(momentum=0.1),\r\n",
        "        keras.layers.ReLU(),\r\n",
        "        keras.layers.DepthwiseConv2D(kernel_size=[3,3],strides=[1, 1], use_bias=False),\r\n",
        "        keras.layers.Conv2D(filters=int(alpha*256), kernel_size=[1, 1], strides=[1,1], use_bias=False),\r\n",
        "        keras.layers.BatchNormalization(momentum=0.1),\r\n",
        "        keras.layers.ReLU(),\r\n",
        "        # Adding a dropout\r\n",
        "        keras.layers.Dropout(0.2),\r\n",
        "        keras.layers.DepthwiseConv2D(kernel_size=[3,3], strides=[1, 1], use_bias=False),\r\n",
        "        keras.layers.Conv2D(filters=int(alpha*256), kernel_size=[1, 1], strides=[1, 1], use_bias=False),\r\n",
        "        keras.layers.BatchNormalization(momentum=0.1),\r\n",
        "        keras.layers.ReLU(),\r\n",
        "        keras.layers.GlobalAveragePooling2D(),\r\n",
        "        keras.layers.Dense(units=8)\r\n",
        "        ])\r\n",
        "\r\n",
        "else:\r\n",
        "    print(\"Invalid model selected\")\r\n",
        "    sys.exit()\r\n",
        "\r\n",
        "\r\n",
        "saved_model_dir = './models/kws'\r\n",
        "\r\n",
        "callbacks = []\r\n",
        "\r\n",
        "if PRUNING is True:\r\n",
        "\r\n",
        "    prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\r\n",
        "\r\n",
        "    pruning_params = {\r\n",
        "        'pruning_schedule':tfmot.sparsity.keras.PolynomialDecay(\r\n",
        "            initial_sparsity=0.50,\r\n",
        "            final_sparsity=0.90,\r\n",
        "            begin_step=len(train_ds)*5,\r\n",
        "            end_step=len(train_ds)*15),\r\n",
        "        # 'block_size':(1, 1),\r\n",
        "        # 'block_pooling_type':'AVG'\r\n",
        "    }\r\n",
        "    \r\n",
        "    callbacks.append(tfmot.sparsity.keras.UpdatePruningStep())\r\n",
        "\r\n",
        "    if mfcc is True:\r\n",
        "        input_shape =[None,49,10,1]\r\n",
        "    \r\n",
        "    else:\r\n",
        "        input_shape = [None,32,32,1]\r\n",
        "\r\n",
        "    model.build(input_shape)\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer='adam',\r\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "            metrics=['accuracy'])\r\n",
        "\r\n",
        "history = model.fit(\r\n",
        "    train_ds,\r\n",
        "    epochs=20,\r\n",
        "    batch_size=32,\r\n",
        "    validation_data=val_ds,\r\n",
        "    callbacks = callbacks\r\n",
        "    )\r\n",
        "\r\n",
        "print(\"Test accuracy:\")\r\n",
        "test_accuracy= model.evaluate(test_ds)\r\n",
        "\r\n",
        "model.summary()\r\n",
        "\r\n",
        "if PRUNING is True:\r\n",
        "    model=tfmot.sparsity.keras.strip_pruning(model)\r\n",
        "\r\n",
        "\r\n",
        "run_model = tf.function(lambda x: model(x))\r\n",
        "\r\n",
        "if mfcc == True:\r\n",
        "    tensor_spec_dimension = [1, 49, 10, 1]\r\n",
        "else:\r\n",
        "    tensor_spec_dimension = [1, 32, 32, 1]\r\n",
        "\r\n",
        "concrete_func = run_model.get_concrete_function(tf.TensorSpec(tensor_spec_dimension, tf.float32))\r\n",
        "model.save(saved_model_dir, signatures=concrete_func)\r\n",
        "\r\n",
        "\r\n",
        "# def representative_data_gen():\r\n",
        "#   for x, _ in train_ds.take(100):\r\n",
        "#     yield [x]\r\n",
        "\r\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\n",
        "\r\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n",
        "\r\n",
        "#converter.representative_dataset = representative_data_gen\r\n",
        "\r\n",
        "#converter.target_spec.supported_types = [tf.float16]\r\n",
        "\r\n",
        "tflite_model = converter.convert()\r\n",
        "\r\n",
        "tflite_model_dir = './models/model.tflite.zlib'\r\n",
        "\r\n",
        "with open(tflite_model_dir, 'wb') as fp:\r\n",
        "    tflite_compressed = zlib.compress(tflite_model)\r\n",
        "    fp.write(tflite_compressed)\r\n",
        "\r\n",
        "print(f\"Size of compressed tflite model: {os.path.getsize(tflite_model_dir)/1024} kB\")\r\n",
        "\r\n",
        "tfModel = tflite_model_dir\r\n",
        "\r\n",
        "str_object1 = open(tflite_model_dir, 'rb').read()\r\n",
        "str_object2 = zlib.decompress(str_object1)\r\n",
        "tfModel = tfModel.replace('.zlib', '')\r\n",
        "f = open(tfModel, 'wb')\r\n",
        "f.write(str_object2)\r\n",
        "f.close()\r\n",
        "\r\n",
        "print(f\"Size of tflite model: {os.path.getsize(tfModel)/1024} kB\")\r\n",
        "\r\n",
        "interpreter = tflite.Interpreter(model_path=tfModel)\r\n",
        "interpreter.allocate_tensors()\r\n",
        "\r\n",
        "input_details = interpreter.get_input_details()\r\n",
        "output_details = interpreter.get_output_details()\r\n",
        "\r\n",
        "input_shape = input_details[0]['shape']\r\n",
        "\r\n",
        "if mfcc is True:\r\n",
        "    tensor_spec =(tf.TensorSpec([None,49,10,1], dtype=tf.float32), tf.TensorSpec([None], dtype=tf.int64))\r\n",
        "else:\r\n",
        "    tensor_spec =(tf.TensorSpec([None,32,32,1], dtype=tf.float32), tf.TensorSpec([None], dtype=tf.int64))\r\n",
        "\r\n",
        "test_ds = tf.data.experimental.load(dataset_dir, tensor_spec) \r\n",
        "test_ds= test_ds.unbatch().batch(1)\r\n",
        "\r\n",
        "accuracy=0\r\n",
        "count= 0 \r\n",
        "for x, y_true in test_ds: \r\n",
        "    interpreter.set_tensor(input_details[0]['index'], x)\r\n",
        "    interpreter.invoke()\r\n",
        "    y_pred = interpreter.get_tensor(output_details[0]['index'])\r\n",
        "    y_pred = y_pred.squeeze()\r\n",
        "    y_pred = np.argmax(y_pred)\r\n",
        "    y_true = y_true.numpy().squeeze()\r\n",
        "    accuracy += y_pred == y_true\r\n",
        "    count += 1 \r\n",
        "\r\n",
        "accuracy/=float(count)\r\n",
        "print(\"Accuracy {}\".format(accuracy*100))\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\n",
            "182083584/182082353 [==============================] - 1s 0us/step\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 42s 208ms/step - loss: 1.5667 - accuracy: 0.5047 - val_loss: 1.0973 - val_accuracy: 0.6850\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.9572 - accuracy: 0.7447 - val_loss: 0.7260 - val_accuracy: 0.8000\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.6896 - accuracy: 0.8170 - val_loss: 0.5334 - val_accuracy: 0.8525\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.5497 - accuracy: 0.8486 - val_loss: 0.4843 - val_accuracy: 0.8612\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4647 - accuracy: 0.8712 - val_loss: 0.3860 - val_accuracy: 0.8963\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4115 - accuracy: 0.8814 - val_loss: 0.3781 - val_accuracy: 0.8825\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3623 - accuracy: 0.8948 - val_loss: 0.3324 - val_accuracy: 0.8950\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3348 - accuracy: 0.9019 - val_loss: 0.3011 - val_accuracy: 0.9175\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3110 - accuracy: 0.9097 - val_loss: 0.2750 - val_accuracy: 0.9100\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.2835 - accuracy: 0.9177 - val_loss: 0.2942 - val_accuracy: 0.9150\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.2701 - accuracy: 0.9172 - val_loss: 0.2543 - val_accuracy: 0.9300\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.2547 - accuracy: 0.9234 - val_loss: 0.2800 - val_accuracy: 0.9187\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.2435 - accuracy: 0.9270 - val_loss: 0.2959 - val_accuracy: 0.9062\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.2259 - accuracy: 0.9295 - val_loss: 0.2522 - val_accuracy: 0.9200\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.2162 - accuracy: 0.9305 - val_loss: 0.2329 - val_accuracy: 0.9212\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.2138 - accuracy: 0.9344 - val_loss: 0.2225 - val_accuracy: 0.9225\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1962 - accuracy: 0.9405 - val_loss: 0.2359 - val_accuracy: 0.9337\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1903 - accuracy: 0.9413 - val_loss: 0.2467 - val_accuracy: 0.9200\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1833 - accuracy: 0.9445 - val_loss: 0.2196 - val_accuracy: 0.9325\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1748 - accuracy: 0.9459 - val_loss: 0.2322 - val_accuracy: 0.9212\n",
            "Test accuracy:\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.9137\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 24, 8, 102)        918       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 24, 8, 102)        408       \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 24, 8, 102)        0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d (DepthwiseC (None, 22, 6, 102)        918       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 22, 6, 102)        10404     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 22, 6, 102)        408       \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 22, 6, 102)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 22, 6, 102)        0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_1 (Depthwis (None, 20, 4, 102)        918       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 20, 4, 102)        10404     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 20, 4, 102)        408       \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 20, 4, 102)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 102)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 824       \n",
            "=================================================================\n",
            "Total params: 25,610\n",
            "Trainable params: 24,998\n",
            "Non-trainable params: 612\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: ./models/kws/assets\n",
            "Size of compressed tflite model: 34.8564453125 kB\n",
            "Size of tflite model: 40.578125 kB\n",
            "Accuracy 91.25\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}