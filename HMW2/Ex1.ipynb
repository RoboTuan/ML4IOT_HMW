{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "Ex1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoboTuan/ML4IOT_HMW/blob/main/Ex1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b4nQVOgzgiv",
        "outputId": "ee7ad1b5-813d-49c3-ce1f-837f387aa8c9"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec 15 08:00:58 2020       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   36C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n|                               |                      |                 ERR! |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwVVtfegzgiw"
      },
      "source": [
        "import argparse\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import tensorflow.lite as tflite\n",
        "import zlib\n",
        "import sys"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuW8x0HNzgiw"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "#parser = argparse.ArgumentParser()\n",
        "#parser.add_argument('--model', type=str, required=True, help='model name')\n",
        "#parser.add_argument('--labels', type=int, required=True, help='model output')\n",
        "#args = parser.parse_args()\n",
        "\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "zip_path = tf.keras.utils.get_file(\n",
        "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
        "    fname='jena_climate_2009_2016.csv.zip',\n",
        "    extract=True,\n",
        "    cache_dir='.', cache_subdir='data')\n",
        "csv_path, _ = os.path.splitext(zip_path)\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "column_indices = [2, 5]\n",
        "columns = df.columns[column_indices]\n",
        "data = df[columns].values.astype(np.float32)\n",
        "\n",
        "n = len(data)\n",
        "train_data = data[0:int(n*0.7)]\n",
        "val_data = data[int(n*0.7):int(n*0.9)]\n",
        "test_data = data[int(n*0.9):]\n",
        "\n",
        "mean = train_data.mean(axis=0)\n",
        "std = train_data.std(axis=0)\n",
        "\n",
        "input_width = 6\n",
        "LABEL_OPTIONS = 2\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip\n",
            "13574144/13568290 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS6_0SA6zgiw",
        "outputId": "89eb908c-b0f6-478c-ed48-6d8e50d6fbba"
      },
      "source": [
        "x = np.array([1,2,3,4,5,6])\n",
        "print(x[-1])\n",
        "print(x[:-3])\n",
        "print(x[-3:])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n[1 2 3]\n[4 5 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj1bKccMzgiw"
      },
      "source": [
        "class WindowGenerator:\n",
        "    def __init__(self, input_width, label_options, mean, std):\n",
        "        self.input_width = input_width\n",
        "        self.label_options = label_options\n",
        "        self.mean = tf.reshape(tf.convert_to_tensor(mean), [1, 1, 2])\n",
        "        self.std = tf.reshape(tf.convert_to_tensor(std), [1, 1, 2])\n",
        "\n",
        "    def split_window(self, features):\n",
        "        input_indeces = np.arange(self.input_width)\n",
        "        inputs = features[:, :-6, :]\n",
        "            \n",
        "        labels = features[:, -6:, :]\n",
        "        num_labels = 2\n",
        "\n",
        "        inputs.set_shape([None, self.input_width, 2])\n",
        "        # vedere se funge\n",
        "        labels.set_shape([None, self.input_width, num_labels])\n",
        "\n",
        "        return inputs, labels\n",
        "\n",
        "    def normalize(self, features):\n",
        "        features = (features - self.mean) / (self.std + 1.e-6)\n",
        "\n",
        "        return features\n",
        "\n",
        "    def preprocess(self, features):\n",
        "        inputs, labels = self.split_window(features)\n",
        "        inputs = self.normalize(inputs)\n",
        "\n",
        "        return inputs, labels\n",
        "\n",
        "    def make_dataset(self, data, train):\n",
        "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
        "                data=data,\n",
        "                # Targets None because we have the targets incorporated in the dataset\n",
        "                targets=None,\n",
        "                sequence_length=input_width+6,\n",
        "                sequence_stride=1,\n",
        "                batch_size=32)\n",
        "        ds = ds.map(self.preprocess)\n",
        "        ds = ds.cache()\n",
        "        if train is True:\n",
        "            ds = ds.shuffle(100, reshuffle_each_iteration=True)\n",
        "\n",
        "        return ds\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sUwT_dQzgix"
      },
      "source": [
        "generator = WindowGenerator(input_width, LABEL_OPTIONS, mean, std)\n",
        "train_ds = generator.make_dataset(train_data, True)\n",
        "val_ds = generator.make_dataset(val_data, False)\n",
        "test_ds = generator.make_dataset(test_data, False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuMCzO_Czgix",
        "outputId": "34fab9af-2fd8-4a21-f9ad-b73fd5a8d430"
      },
      "source": [
        "for element in train_ds:\n",
        "    print(len(element))\n",
        "    print(element[0].shape, element[1].shape)\n",
        "    #print(element[0])\n",
        "    sys.exit()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n(32, 6, 2) (32, 6, 2)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOG_bjOkzgix"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCCQPQXLzgix"
      },
      "source": [
        "MODEL_OPTIONS = \"CNN-1D\"\n",
        "ALPHA = 1\n",
        "\n",
        "units=6*2\n",
        "\n",
        "\n",
        "if MODEL_OPTIONS == \"MLP\":\n",
        "    model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(6, 2)),\n",
        "    keras.layers.Dense(units=int(128*ALPHA), activation='relu', name='first_dense'),\n",
        "    keras.layers.Dense(units=int(128*ALPHA), activation='relu', name='second_dense'),\n",
        "    keras.layers.Dense(units, name='third_dense'),\n",
        "    keras.layers.Reshape([6, 2])\n",
        "    ])\n",
        "\n",
        "\n",
        "elif MODEL_OPTIONS == \"CNN-1D\":\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Conv1D(filters=int(64*ALPHA), kernel_size=3, activation='relu', name='first_conv'),\n",
        "        keras.layers.Flatten(input_shape=(64,)),\n",
        "        keras.layers.Dense(units=int(64*ALPHA), activation='relu', name='first_dense'),\n",
        "        keras.layers.Dense(units, name='second_dense'),\n",
        "        keras.layers.Reshape([6, 2])\n",
        "    ])\n",
        "\n",
        "# WARNING: DO NOT USE LSTM MODEL\n",
        "# NOT STABLE WITH TFLITE\n",
        "# elif MODEL_OPTIONS == \"LSTM\":\n",
        "#     model = keras.Sequential([\n",
        "#         keras.layers.LSTM(64),\n",
        "#         keras.layers.Flatten(),\n",
        "#         keras.layers.Dense(units),\n",
        "#         keras.layers.Reshape([6, 2])\n",
        "#     ])\n",
        "\n",
        "else:\n",
        "    print(\"Invalid model selected\")\n",
        "    sys.exit()\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROJvK7V5zgix"
      },
      "source": [
        "# TODO: \n",
        "# pass a single list of dimension to the reduce_mean function\n",
        "# see pdf for more instructions\n",
        "class MsMoMAE(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='MsMoMAE', **kwargs):\n",
        "        super(MsMoMAE, self).__init__(name=name, **kwargs)\n",
        "        self.total = self.add_weight(name='total', initializer='zeros', shape=(2, ))\n",
        "        self.count = self.add_weight(name='count', initializer='zeros')\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.count.assign(tf.zeros_like(self.count))\n",
        "        self.total.assign(tf.zeros_like(self.total))\n",
        "\n",
        "        return\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        error = tf.abs(y_pred - y_true)\n",
        "        #error = tf.reduce_mean(error, axis=1)\n",
        "        #error = tf.reduce_mean(error, axis=0)\n",
        "        error = tf.reduce_mean(error, axis=[0,1])\n",
        "        self.total.assign_add(error)\n",
        "        self.count.assign_add(1)\n",
        "\n",
        "        return\n",
        "\n",
        "    def result(self):\n",
        "        result = tf.math.divide_no_nan(self.total, self.count)\n",
        "\n",
        "        return result\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRo_w--Uzgiy",
        "outputId": "dd59bf13-a437-49ea-8344-88b6c189d128"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "            loss=[tf.keras.losses.MeanSquaredError()],\n",
        "            metrics=[MsMoMAE()])\n",
        "\n",
        "print(\"Fit model on training data\")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    batch_size=32,\n",
        "    epochs=20,\n",
        "    validation_data=(val_ds)\n",
        ")\n",
        "\n",
        "print(\"Evaluate on test data\")\n",
        "loss, error = model.evaluate(test_ds, verbose=2)\n",
        "print(error)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit model on training data\n",
            "Epoch 1/20\n",
            "9200/9200 [==============================] - 54s 6ms/step - loss: 49.3406 - MsMoMAE: 2.6239 - val_loss: 4.9295 - val_MsMoMAE: 1.2850\n",
            "Epoch 2/20\n",
            "9200/9200 [==============================] - 31s 3ms/step - loss: 5.1622 - MsMoMAE: 1.3254 - val_loss: 5.8254 - val_MsMoMAE: 1.5140\n",
            "Epoch 3/20\n",
            "9200/9200 [==============================] - 31s 3ms/step - loss: 4.8162 - MsMoMAE: 1.2669 - val_loss: 5.5697 - val_MsMoMAE: 1.4541\n",
            "Epoch 4/20\n",
            "9200/9200 [==============================] - 32s 3ms/step - loss: 4.7534 - MsMoMAE: 1.2528 - val_loss: 5.8837 - val_MsMoMAE: 1.4134\n",
            "Epoch 5/20\n",
            "9200/9200 [==============================] - 31s 3ms/step - loss: 4.6003 - MsMoMAE: 1.2159 - val_loss: 4.9118 - val_MsMoMAE: 1.2966\n",
            "Epoch 6/20\n",
            "9200/9200 [==============================] - 31s 3ms/step - loss: 4.5110 - MsMoMAE: 1.1978 - val_loss: 5.6140 - val_MsMoMAE: 1.5401\n",
            "Epoch 7/20\n",
            "9200/9200 [==============================] - 31s 3ms/step - loss: 4.4321 - MsMoMAE: 1.1864 - val_loss: 5.7029 - val_MsMoMAE: 1.4282\n",
            "Epoch 8/20\n",
            "9200/9200 [==============================] - 31s 3ms/step - loss: 4.3609 - MsMoMAE: 1.1739 - val_loss: 4.1128 - val_MsMoMAE: 1.0635\n",
            "Epoch 9/20\n",
            "9200/9200 [==============================] - 31s 3ms/step - loss: 4.3415 - MsMoMAE: 1.1700 - val_loss: 4.9335 - val_MsMoMAE: 1.4216\n",
            "Epoch 10/20\n",
            "9200/9200 [==============================] - 31s 3ms/step - loss: 4.3188 - MsMoMAE: 1.1583 - val_loss: 4.3007 - val_MsMoMAE: 1.1439\n",
            "Epoch 11/20\n",
            "9200/9200 [==============================] - 31s 3ms/step - loss: 4.2813 - MsMoMAE: 1.1496 - val_loss: 4.2510 - val_MsMoMAE: 1.1463\n",
            "Epoch 12/20\n",
            "9200/9200 [==============================] - 31s 3ms/step - loss: 4.2475 - MsMoMAE: 1.1414 - val_loss: 4.1790 - val_MsMoMAE: 1.1151\n",
            "Epoch 13/20\n",
            "9200/9200 [==============================] - 31s 3ms/step - loss: 4.2454 - MsMoMAE: 1.1415 - val_loss: 4.1574 - val_MsMoMAE: 1.0658\n",
            "Epoch 14/20\n",
            "9200/9200 [==============================] - 32s 3ms/step - loss: 4.1650 - MsMoMAE: 1.1248 - val_loss: 5.6492 - val_MsMoMAE: 1.4703\n",
            "Epoch 15/20\n",
            "9200/9200 [==============================] - 31s 3ms/step - loss: 4.1787 - MsMoMAE: 1.1282 - val_loss: 4.9500 - val_MsMoMAE: 1.3140\n",
            "Epoch 16/20\n",
            "9200/9200 [==============================] - 31s 3ms/step - loss: 4.1702 - MsMoMAE: 1.1266 - val_loss: 4.0217 - val_MsMoMAE: 1.0775\n",
            "Epoch 17/20\n",
            "9200/9200 [==============================] - 32s 3ms/step - loss: 4.1417 - MsMoMAE: 1.1239 - val_loss: 4.4249 - val_MsMoMAE: 1.1951\n",
            "Epoch 18/20\n",
            "9200/9200 [==============================] - 31s 3ms/step - loss: 4.1119 - MsMoMAE: 1.1163 - val_loss: 4.9005 - val_MsMoMAE: 1.2590\n",
            "Epoch 19/20\n",
            "9200/9200 [==============================] - 31s 3ms/step - loss: 4.1110 - MsMoMAE: 1.1186 - val_loss: 4.3156 - val_MsMoMAE: 1.1322\n",
            "Epoch 20/20\n",
            "9200/9200 [==============================] - 31s 3ms/step - loss: 4.0793 - MsMoMAE: 1.1085 - val_loss: 3.8870 - val_MsMoMAE: 1.0293\n",
            "Evaluate on test data\n",
            "1314/1314 - 5s - loss: 4.0324 - MsMoMAE: 1.0705\n",
            "[0.41685838 1.7242216 ]\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "first_conv (Conv1D)          (None, 4, 64)             448       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "first_dense (Dense)          (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "second_dense (Dense)         (None, 12)                780       \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 6, 2)              0         \n",
            "=================================================================\n",
            "Total params: 17,676\n",
            "Trainable params: 17,676\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSd7BSXLy4rY",
        "outputId": "446f7478-8936-4cd4-a629-0501b1d0914a"
      },
      "source": [
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "\n",
        "pruning_params = {'pruning_schedule':\n",
        "                tfmot.sparsity.keras.PolynomialDecay(\n",
        "                    initial_sparsity=0.30,\n",
        "                    final_sparsity=0.8,\n",
        "                    begin_step=len(train_ds)*5,\n",
        "                    end_step=len(train_ds)*15)}\n",
        "\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model)\n",
        "\n",
        "\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "            loss=[tf.keras.losses.MeanSquaredError()],\n",
        "            metrics=[MsMoMAE()])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "#tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir)\n",
        "]\n",
        "\n",
        "print(\"Fine tune pruned model\")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    batch_size=32,\n",
        "    epochs=2,\n",
        "    validation_data=(val_ds)\n",
        ")\n",
        "\n",
        "print(\"Evaluate on test data\")\n",
        "loss, error = model.evaluate(test_ds, verbose=2)\n",
        "print(error)\n",
        "\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:200: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "first_conv (Conv1D)          (None, 4, 64)             448       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "first_dense (Dense)          (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "second_dense (Dense)         (None, 12)                780       \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 6, 2)              0         \n",
            "=================================================================\n",
            "Total params: 17,676\n",
            "Trainable params: 17,676\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fine tune pruned model\n",
            "Epoch 1/2\n",
            "9200/9200 [==============================] - 31s 3ms/step - loss: 4.0514 - MsMoMAE: 1.1017 - val_loss: 5.4049 - val_MsMoMAE: 1.3524\n",
            "Epoch 2/2\n",
            "9200/9200 [==============================] - 31s 3ms/step - loss: 4.0765 - MsMoMAE: 1.1103 - val_loss: 5.2791 - val_MsMoMAE: 1.4215\n",
            "Evaluate on test data\n",
            "1314/1314 - 2s - loss: 5.1750 - MsMoMAE: 1.4044\n",
            "[0.49177316 2.3169835 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8AyvOXBzgiy",
        "outputId": "05f6b153-ca02-46ca-8ea5-b9e901a2e89a"
      },
      "source": [
        "PTQ = \"weights_activations\"\n",
        "MAGPRUNE = True\n",
        "\n",
        "if MAGPRUNE == True:\n",
        "    model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "    final_model = model_for_export\n",
        "else:\n",
        "    final_model = model\n",
        "\n",
        "saved_model_dir = './models/climate_{}_{}'.format(MODEL_OPTIONS, str(LABEL_OPTIONS))\n",
        "\n",
        "if not os.path.exists('./models'):\n",
        "    os.makedirs('./models')\n",
        "\n",
        "if not os.path.exists(saved_model_dir):\n",
        "    os.makedirs(saved_model_dir)\n",
        "final_model.save(saved_model_dir)\n",
        "\n",
        "\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "tflite_model_dir = './models/tflite_climate_{}_{}_{}_{}_{}'.format(MODEL_OPTIONS, str(LABEL_OPTIONS), PTQ, str(ALPHA), str(MAGPRUNE))\n",
        "\n",
        "\n",
        "if PTQ.lower() == 'weights':\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "elif PTQ.lower() == 'weights_activations':\n",
        "\n",
        "    def representative_dataset_gen():\n",
        "        for x, _ in train_ds.take(1000):\n",
        "            yield [x]\n",
        "\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    converter.representative_dataset = representative_dataset_gen\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "else:\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "if MAGPRUNE == True:\n",
        "    tflite_model_dir = tflite_model_dir + \".zip\"\n",
        "    with open(tflite_model_dir, 'wb') as fp:\n",
        "        tflite_compressed = zlib.compress(tflite_model)\n",
        "        fp.write(tflite_compressed)\n",
        "    print(f\"Size of tflite model: {os.path.getsize(tflite_model_dir)} bytes\")\n",
        "    \n",
        "else:\n",
        "    with open(tflite_model_dir, 'wb') as fp:\n",
        "        fp.write(tflite_model)\n",
        "    print(f\"Size of tflite model: {os.path.getsize(tflite_model_dir)} bytes\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: ./models/climate_CNN-1D_2/assets\n",
            "Size of tflite model: 14570 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoOCKAydy4rZ"
      },
      "source": [
        "#!rm -rf ./models"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR4vxKF2y4ra",
        "outputId": "ce366a8d-54be-4950-9f6b-78468012285c"
      },
      "source": [
        "print(f\"Size of tflite model: {os.path.getsize('./models/tflite_climate_CNN-1D_2_noPTQ_1')} bytes\")\n",
        "print(f\"Size of tflite model: {os.path.getsize('./models/tflite_climate_CNN-1D_2_weights_1')} bytes\")\n",
        "print(f\"Size of tflite model: {os.path.getsize('./models/tflite_climate_CNN-1D_2_weights_activations_1')} bytes\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of tflite model: 75740 bytes\n",
            "Size of tflite model: 26848 bytes\n",
            "Size of tflite model: 26320 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8e7VoFRy4rb"
      },
      "source": [
        "str_object1 = open('./models/tflite_climate_CNN-1D_2_weights_activations_1_True.zip', 'rb').read()\n",
        "str_object2 = zlib.decompress(str_object1)\n",
        "f = open('./models/tflite_climate_CNN-1D_2_weights_activations_1_True', 'wb')\n",
        "f.write(str_object2)\n",
        "f.close()\n",
        "\n",
        "interpreter = tflite.Interpreter(model_path=\"./models/tflite_climate_CNN-1D_2_weights_activations_1_True\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n"
      ],
      "execution_count": 22,
      "outputs": []
    }
  ]
}